Why Store State in S3?

By default, Terraform saves state in terraform.tfstate (local file).

Problems with local state:

Only you have it â†’ teammates wonâ€™t see changes.

Risk of corruption or loss.

Multiple people applying at the same time = conflicts.

âœ… Solution â†’ Remote State in S3 + State Locking with DynamoDB.


Create an S3 Bucket
-------------------
    bash 
    ----
    aws s3api create-bucket \
  --bucket my-terraform-state-bucket \
  --region ap-south-1 \
  --create-bucket-configuration LocationConstraint=ap-south-1


=> better way is to Enable versioning (so you can roll back state if needed):
    bash
    ----
    aws s3api put-bucket-versioning \
  --bucket my-terraform-state-bucket \
  --versioning-configuration Status=Enabled
  --create-bucket-configuration LocationConstraint=ap-south-1

Create a DynamoDB Table (for locking)
------------------------------------
=> Terraform can use DynamoDB to prevent two people running apply at the same time.
    bash
    ----
    aws dynamodb create-table \
  --table-name terraform-locks \
  --attribute-definitions AttributeName=LockID,AttributeType=S \
  --key-schema AttributeName=LockID,KeyType=HASH \
  --billing-mode PAY_PER_REQUEST

Configure Backend in Terraform
------------------------------
=> Create a file backend.tf (or add to main.tf)
    hcl 
    ----
    terraform {
        backend "s3" {
            bucket         = "my-terraform-state-bucket"
            key            = "dev/terraform.tfstate"
            region         = "us-east-1"
            dynamodb_table = "terraform-locks"
            encrypt        = true
        }
    }

Initialize Backend
------------------
    bash
    -----
    terraform init

=> Terraform will detect the backend config and ask to migrate your local state to S3.
    Type yes â†’ it uploads terraform.tfstate to S3.




-----------------------------------------------------------------------------------------------------------------------------------------------------------------

Weâ€™ll use a two-project approach:

Bootstrap Project â†’ Creates S3 + DynamoDB (for state storage & locking).

Main Project â†’ Uses that backend to manage your real infra (EC2, DBs, etc.).

this help us to create and delete everything in one shot.


Bootstrap Project
------------------
Create a folder
    bash
    ----
    mkdir terraform-bootstrap
    cd terraform-bootstrap

=> Inside, create main.tf
    hcl
    ----
provider "aws" {
  region = "ap-south-1"
}

# S3 bucket for Terraform state
resource "aws_s3_bucket" "tf_state" {
  bucket = "terraform-state-naveen-20250905"
}

# Enforce bucket owner (no ACLs needed)
resource "aws_s3_bucket_ownership_controls" "tf_state" {
  bucket = aws_s3_bucket.tf_state.id

  rule {
    object_ownership = "BucketOwnerEnforced"
  }
}

# Enable versioning (for rollback safety)
resource "aws_s3_bucket_versioning" "tf_state" {
  bucket = aws_s3_bucket.tf_state.id

  versioning_configuration {
    status = "Enabled"
  }
}

# Encrypt state at rest
resource "aws_s3_bucket_server_side_encryption_configuration" "tf_state" {
  bucket = aws_s3_bucket.tf_state.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# DynamoDB table for state locking
resource "aws_dynamodb_table" "tf_locks" {
  name         = "terraform-locks"
  billing_mode = "PAY_PER_REQUEST"

  hash_key = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }
}


Run it
--------
    bash 
    ----
    terraform init
    terraform apply

âœ… Terraform will now use S3 + DynamoDB from the bootstrap project.
State is no longer local â€” check your bucket and table in AWS Console.


Main Project
-------------

=> Create another folder for your real infra:

    bash
    -----
    mkdir terraform-main
    cd terraform-main

=> backend.tf

terraform {
  backend "s3" {
    bucket         = "terraform-state-naveen-20250905"
    key            = "dev/terraform.tfstate"
    region         = "ap-south-1"
    dynamodb_table = "terraform-locks"
    encrypt        = true
  }
}



ðŸ‘‰ Note: This file does not define resources. It only tells Terraform where to store state.
ðŸ‘‰ Note: if already statetf (local file ) is created then do update
    bash
    -----
    terraform init -migrate-state



Then, create main.tf for your infra (example EC2):

hcl
-----
provider "aws" {
  region = "ap-south-1"
}

resource "aws_instance" "demo" {
  ami           = "ami-0f5ee92e2d63afc18" # Example Ubuntu 22.04 AMI for ap-south-1
  instance_type = "t2.micro"

  tags = {
    Name = "TerraformDemo"
  }
}


Run :

terraform init
terraform apply

âœ… Terraform will now use S3 + DynamoDB from the bootstrap project.
State is no longer local â€” check your bucket and table in AWS Console.

Destroying
----------

If you destroy your main project â†’ EC2 instance and other infra will go, but state backend (S3 + DynamoDB) remains.

If you later want to remove backend infra too â†’ run terraform destroy inside the bootstrap project.

This separation keeps your backend safe and reusable across environments (dev, prod, etc.).

